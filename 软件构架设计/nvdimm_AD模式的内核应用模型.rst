.. Kenneth Lee 版权所有 2020

:Authors: Kenneth Lee
:Version: 1.0

nvdimm AD模式的内核应用模型
***************************

本文用于相关考虑展开第一层逻辑，作者只花了几个小时查看相关资料，里面的判断不一
定是对的，欢迎在读者参与讨论，并指出其中的错漏。

nvdimm是Non-Volatile DIMM的缩写，概念上表示把SSD等非易失存储实现成DIMM条，直接
插入内存插槽中使用。一般认为这种dimm条比内存慢，但比SSD块（因为挂的总线更近），
价钱比DRAM便宜，比SSD贵。

nvdimm有两种使用模式：Memory Mode（以下简称mm）和App Direct Mode（以下简称AD）
。前者表示直接当内存用，后者表示让应用感知，当存储设备用。

前者没有什么可说的，是个硬件方案，软件除了在优化上可能有点变动外，基本上可以当
它透明。后者是我们关注的重点。

当前Linux内核对这个特性的实现有三种抽象：

1. dimm：一条dimm一个设备

2. blk：把dimm条中部分空间抽出来作为一个设备

3. pmem：把多条dimm条合并交织使用提高带宽

三种抽象都可以给使用者呈现为region，region是一片“看来连续”的地址空间，应用程序
通过mmap这片空间对其中的内容进行访问。

Region不实现为一般磁盘所实现的block device。因为它不需要成块访问，也不需要使用
page cache机制。所以内核中创建了一个新的框架，称为dax，Direct Access for X，原
理就是直接mmap对应的物理空间，然后直接访问，中间没有块的组合和page cache的缓冲
。

但即使是DRAM，都会有数据仍在Cache上的情形，所以，断电仍可能造成静态数据的损坏，
所以使用者需要自己知道在什么时候进行原子操作，并保证数据被flush到nvdimm内存中。
nvdimm对此进行了另一层封装，称为BTT，block translation table。BTT以最大512G为单
位把数据进行规整化管理，把数据分成map区和数据区，保证数据更新是原子化的。

用户态程序通过libnvdimm对上述访问进行封装，主要提供helpper函数支持上述概念的访
问。现在这个支持已经扩大了，形成了一组开发库：

        pmem.io: PMDK

我们再花点时间讨论一下MM模式。有人想着把nvdimm用做普通内存，但很难接受它这么慢
，考虑把这个问题推给NUMA，把nvdimm的内存放到另一个NUMA节点上。但这就算不上是一
种“解决方案”，因为这本来就是你这个内存的“属性”，你最多就算招供，不算是解决方案
，对吧？

另一个角度来说，我们提出NUMA，可不是为了说这个内存慢，而是为了强调进程的内存的
距离。我们认知NUMA的存在，是希望把进程和内存靠近了放，然后你这个nvdimm跟谁都“不
近”，那没有什么意义。

我一时是想不到有什么应用，会接受把一部分内存故意放在远内存，一部分数据放在近内
存上的，除非我本来就打算老老实实做Cache，但如果我老老实实做Cache，我何必让软件
管这个呢？直接把DRAM做L4，NVDIMM做L5好了。

我个人是比较容易接受MM模式就是一种低价内存方案，或者就应该发挥它NV的特点，用在
AD模式上。
